<!DOCTYPE HTML>
<!--
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>

<head>
	<title>Wenjia Xu | Research Associate Professor, PhD Advisor @ Beijing University of Posts and Telecommunications</title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="" />
	<meta name="keywords" content="" />
	<noscript>
		<link rel="stylesheet" href="css/style.css" />
		<link rel="stylesheet" href="css/skel.css" />
		<link rel="stylesheet" href="css/style-xlarge.css" />
	</noscript>
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Raleway:400,700">
	<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans">
	<link rel="stylesheet" href="css/font-awesome.min.css">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<!--[if lte IE 8]><script src="js/html5shiv.js"></script><![endif]-->
	<script src="js/jquery.min.js"></script>
	<script src="js/skel.min.js"></script>
	<script src="js/skel-layers.min.js"></script>
	<script src="js/init.js"></script>
	<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>

<body class="landing">

	<!-- Header -->
	<header id="header">
		<ul class="icons">
			<li>
				<a href="https://scholar.google.com/citations?hl=zh-CN&view_op=list_works&gmla=AJsN-F7yMm5OlAmC4AgsrvACdQGDAKL16e4QE2b4shc6AFrgJxLhUpqKlGIMRBjmqI4eeQfPQHuptdiyWKBSzuC5gHwerEQD3smq--LlKeOtMuNHlBWxVuY&user=mW2Jtu0AAAAJ" class="icon fa-graduation-cap"></a>
			</li>
			<li>
				<a href="https://github.com/wenjiaXu" class="icon fa-github"></a>
			</li>
			<li>
				<a href="https://twitter.com/wenjia43411575" class="icon fa-twitter"></a>
			</li>
			<li>
				<a href="https://www.linkedin.com/in/%E6%96%87%E5%98%89-%E8%AE%B8-440867139/" class="icon fa-linkedin"></a>
			</li>
		</ul>
		<nav id="nav">
			<ul>
				<li><a href="/" class="active">Home</a></li>
				<li><a href="/#two">Publications</a></li>
				<li><a href="/graph-convolutional-networks/">Blog</a></li>
				<li><a href="/#footer">Contact</a></li>
			</ul>
		</nav>
	</header>

	<!-- One -->
	<section id="one" class="wrapper style1">
		<div class="container 75%">
			<div class="row 200%">
				<div class="6u 12u$(medium)">
					<header class="major">
						<h2>Wenjia Xu (许文嘉)</h2>
						<p>
							<div class="image rounded" style="margin-bottom: 1.5em;"><img src="images/photo2.jpeg" width="200" alt="" /></div>
						</p>
						<p>Research Associate Professor, PhD Advisor</p>
						<p>Beijing University of Posts and Telecommunications</p>
					</header>
				</div>
				<div class="6u$ 12u$(medium)">
					<p>Currently I am a research associate professor at School of Information and Communication Engineering, Beijing University of Posts and Telecommunications.</p>
					
					<p>My research lies at the intersection of computer vision, natural language processing, and remote sensing, which covers a wide range of topics including remote sensing scene classification, few-shot learning, image captioning, explainable artificial inteligience.</p>


					<p>I got my PhD degree from University of Chinese Academy of Sciences, advised by <a href="http://people.ucas.ac.cn/~0001014?language=en" target="_blank">Prof. Yirong Wu</a>. During my PhD, I'm also co-supervised by <a href="https://eml-unitue.de/people/zeynep-akata" target="_blank">Prof. Zeynep Akata</a> and <a href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele/" target="_blank">Prof. Bernt Schiele</a> at <a href="https://www.mpi-inf.mpg.de/home/" target="_blank">Max Plank Institute for Informatics</a>. I got my Bachelar's degree with horner from <a href="http://english.bit.edu.cn/" target="_blank">Beijing Institute of Technology</a> at 2016. During Jan.2016 - Jul.2016, I finished my bachelor thesis under the supervision of <a href="https://www.kth.se/profile/oech" target="_blank">Prof. Tobias Oechtering</a> at <a href="https://www.kth.se/" target="_blank">KTH</a>.</p>
					
					
<!-- 					<b><font color="#FF0000">I'm always looking for highly self-motivated PhD/master students, visiting students, and undergraduate interns (RAs) to work with me. Please directly send your CV to me if you find my research interesting.</font></b> -->
			
			</div>
			</div>
		</div>
		<div class="container 75%">
			<b><font color="#FF0000">I'm always looking for highly self-motivated PhD/master students, visiting students, and undergraduate interns (RAs) to work with me. Please directly send your CV to me (xuwenjia [AT] bupt.edu.cn) if you find my research interesting.</font></b>

		</div>

		<div class="container 75%">
			<h3 style="text-align: center">News</h3>
			<ul>
				<li>04/2022: Our paper about Zero-Shot Learning is accepted by IJCAI 2022.</li>

				<li>03/2022: Our paper about Zero-Shot Learning is accepted by IJCV.</li>

				<li>03/2022: Our paper about distinctive image captioning is accepted by TPAMI.</li>
				
				<li>03/2022: Our paper about Zero-Shot Learning is accepted by CVPR 2022.</li>
				
				<li>01/2022: I am awarded the National Scholarship for Graduate Students by MOE (Ministry Of Education).</li>

				<li>10/2021: Our paper about the intersaction of XAI and gaze is accepted by BMVC 2021.</li>

<!-- 				<li>07/2021: Give an invited talk at Beihang University.</li> -->
				
				<li>06/2021: One paper about distinctive image captioning is accepted by ACM MM 2021 as <span style="font-weight: bold; color: #DC143C">Oral</span>.</li>

				<li>09/2020: One paper about Zero-Shot Learning is accepted by NeurIPS 2020.</li>

				<li>07/2020: One paper about distinctive image captioning is accepted by ECCV 2020 as <span style="font-weight: bold; color: #DC143C">Oral</span>.</li>
				
				<li>07/2020: Two workshop papers accepted by ECCV 2020.</li>
				
<!-- 				<li>01/2020: One paper accepted by IEEE Journal of Selected Topics in Signal Processing.</li> -->

<!-- 				<li>12/2019: Two papers accepted by Knowledge-based Systems.</li> -->

<!-- 				<li>09/2019: I get to Max Plank Institute as a visiting researcher, working with Prof. Zeynep Akata and Prof. Bernt Schiele.</li> -->

<!-- 				<li>06/2019: I get to University of Amsterdam as a visiting researcher, working with Prof. Zeynep Akata.</li> -->
				
<!-- 				<li>12/2018: One paper accepted by Remote Sensing.</li>
				
<!-- 				<li>06/2018: One paper accepted by IGARSS2018 as <span style="font-weight: bold; color: #DC143C">Oral</span>.</li> -->
				
			</ul>
		</div>
	</section>

	<!-- Two -->
	<section id="two" class="wrapper style2">
		<div class="container 75%">
			<h2 style="text-align: center">Selected Publications</h2>
			<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/APN_IJCV.png" width="220" alt="" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Attribute Prototype Network for Any-Shot Learning</h4>
						<p>International Journal of Computer Vision, IJCV, 2022</p>
					</header>
					<p><span style="text-decoration: underline;">Wenjia Xu</span>, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata,
							 [<a href='https://arxiv.org/abs/2204.01208'>PDF</a>, <a href='https://wenjiaxu.github.io/APN-ZSL/'>Project Page</a>, <a href='https://github.com/wenjiaXu/APN-ZSL'>Code</a>]. </p>
				</div>
			</div>
			<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/VGSE.png" width="220" alt=""/></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Visually-Grounded Semantic Embeddings for Zero-Shot Learning</h4>
						<p>IEEE Conference on Computer Vision and Pattern Recognition, CVPR, 2022</p>
					</header>
					<p><span style="text-decoration: underline;">Wenjia Xu</span>, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata,
						[<a href='https://arxiv.org/abs/2203.10444'>PDF</a>, <a href='https://wenjiaxu.github.io/VGSE-ZSL/'>Project Page</a>, <a href='https://github.com/wenjiaXu/VGSE'>Code</a>]. </p>
				</div>
			</div>
			<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/TPAMI22.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>On Distinctive Image Captioning via Comparing and Reweighting</h4>
						<p>IEEE Transactions on Pattern Analysis and Machine Intelligence, TPAMI, 2022</p>
					</header>
					<p>Jiuniu Wang*, <span style="text-decoration: underline;">Wenjia Xu*</span>, Qingzhong Wang, Antoni B. Chan, (* = equal contribution)
						[<a href='https://arxiv.org/abs/2204.03938'>PDF</a>]. </p>
				</div>
			</div>
			<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/BMVC21.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Human Attention in Fine-Grained Classification</h4>
						<p>British Machine Vision Conference, BMVC, 2021</p>
					</header>
					<p>Yao Rong, <span style="text-decoration: underline;">Wenjia Xu</span>, Zeynep Akata, Enkelejda Kasneci,
						[<a href='https://arxiv.org/abs/2111.01628'>PDF</a>]. </p>
				</div>
			</div>
			<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/ACMMM21.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Group-based distinctive image captioning with memory attention</h4>
						<p>Proceedings of the 29th ACM International Conference on Multimedia, ACMMM, 2021</p>
					</header>
					<p>Jiuniu Wang, <span style="text-decoration: underline;">Wenjia Xu</span>, Qingzhong Wang, Antoni B. Chan,
						[<a href='https://arxiv.org/abs/2108.09151'>PDF</a>]. </p>
				</div>
			</div>
			<hr />
 			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/APN.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Attribute Prototype Network for Zero-Shot Learning</h4>
						<p>Neural Information Processing Systems, NeurIPS, 2020</p>
					</header>
					<p><span style="text-decoration: underline;">Wenjia Xu</span>, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata,
						[<a href='https://arxiv.org/pdf/2008.08290.pdf'>PDF</a>, <a href='https://wenjiaxu.github.io/APN-ZSL/'>Project Page</a>]. </p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/ciderbtw.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets</h4>
						<p>European Conference on Computer Vision, ECCV, 2020 </p>
					</header>
					<p>Jiuniu Wang, <span style="text-decoration: underline;">Wenjia Xu</span>, Qingzhong Wang, Antoni B Chan, 
						<span style="font-weight: bold; color: #DC143C">Oral</span>,  [<a href='https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460358.pdf'>PDF</a>, <a href='https://wenjiaxu.github.io/ciderbtw/'>Project Page</a>]. </p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/where.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Where is the Model Looking At --Concentrate and Explain the Network Attention</h4>
						<p>IEEE Journal of Selected Topics in Signal Processing, JSTSP, 2020</p>
					</header>
					<p><span style="text-decoration: underline;">Wenjia Xu</span>, Jiuniu Wang, Yang Wang, Guangluan Xu, Daoyu Lin, Wei Dai, Yirong Wu,  [<a href='https://ieeexplore.ieee.org/abstract/document/9067082'>Link</a>, <a href='https://arxiv.org/abs/2009.13862'>PDF</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/ARS.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>ASTRAL: Adversarial Trained LSTM-CNN for Named Entity Recognition</h4>
						<p>Knowledge-Based Systems, KBS, 2020</p>
					</header>
					<p>Jiuniu Wang, <span style="text-decoration: underline;">Wenjia Xu*</span>, Xingyu Fu, Guangluan Xu, Yirong Wu,
					(* = corresponding author),   [<a href='https://www.sciencedirect.com/science/article/abs/pii/S0950705120302136'>Link</a>, <a href="https://arxiv.org/abs/2009.01041">PDF</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/SRQA.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>SRQA: Synthetic Reader for Factoid Question Answering</h4>
						<p>Knowledge-Based Systems, KBS, 2020</p>
					</header>
					<p>Jiuniu Wang, <span style="text-decoration: underline;">Wenjia Xu*</span>, Xingyu Fu, Yang Wei, Li Jin, Ziyan Chen, Guangluan Xu, Yirong Wu, (* = corresponding author), [<a href='https://www.sciencedirect.com/science/article/abs/pii/S0950705119306471'>Link</a>, <a href="https://arxiv.org/abs/2009.01630">PDF</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/DMC.jpg" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>Deep Memory Connected Neural Network for Optical Remote Sensing Image Restoration</h4>
						<p>Remote Sensing</p>
					</header>
					<p><span style="text-decoration: underline;">Wenjia Xu</span>, Guangluan Xu, Yang Wang, Xian Sun, Daoyu Lin, Yirong Wu,
 [<a href='https://www.mdpi.com/2072-4292/10/12/1893'>PDF</a>, <a href="https://github.com/wenjiaXu/Optical-RemoteSensing-Image-Resolution">code</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/SCRSR.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>SCRSR: An efficient recursive convolutional neural network for fast and accurate image super-resolution</h4>
						<p>Neurocomputing</p>
					</header>
					<p> Daoyu Lin, Guangluan Xu, <span style="text-decoration: underline;">Wenjia Xu</span>, Yang Wang, Xian Sun, Kun Fu
 
						[<a href='https://www.sciencedirect.com/science/article/abs/pii/S0925231219314572'>Link&PDF</a>].</p>
				</div>
			</div>
			<hr />
			<div class="row 200%">
				<div class="3u 4u(large) 12u$(medium)">
						<div class="image"><img src="images/igarss2018.png" width="220" alt="" style="border:none;" /></div>
				</div>
				<div class="9u$ 8u$(large) 12u$(medium)">
					<header>
						<h4>High Quality Remote Sensing Image Super-Resolution Using Deep Memory Connected Network</h4>
						<p>IEEE International Symposium on Geoscience and Remote Sensing, IGARSS, 2018</p>
					</header>
					<p><span style="text-decoration: underline;">Wenjia Xu</span>, Guangluan Xu, Yang Wang, Xian Sun, Daoyu Lin, Wu Yirong,
<span style="font-weight: bold; color: #DC143C">Oral</span> ,[<a href='https://arxiv.org/abs/2010.00472'>PDF</a>].</p>
				</div>
			</div>
			<hr />
			<p style="text-align:center;">For a full list, have a look at my <a href="https://scholar.google.com/citations?hl=zh-CN&user=mW2Jtu0AAAAJ">Google Scholar</a> page.</p>
		</div>
	</section>


	<!-- Three -->
	
	<section id="three" class="wrapper style1">
		<div class="container 75%">
			<h3 style="text-align: center">Services</h3>
			<ul>
		<li>Reviewer for IJCV since 2022.</li>
				
		<li>Reviewer for TIP since 2022.</li>

                <li>Reviewer for Knowledge-Based Systems, The Visual Computer since 2020.</li>
				
                <li>Reviewer for Future Generation Computer Systems since 2021.</li>

                <li>Reviewer for ICLR 2021, NeurIPS 2021, AAAI 2021, CVPR 2022, NeurIPS 2022, AAAI 2022, CVPR 2023.</li>
								
			</ul>
		</div>
	</section>
	
	<!-- Four -->
	
	<section id="three" class="wrapper style3 special">
		<div class="container 50%">

			<h2>Curriculum vitae</h2>
			<ul class="actions">
				<li><a href="CV_Wenjia.pdf" class="button alt big">Download CV</a></li>
			</ul>
		</div>
	</section>


	<!-- Footer -->
	<footer id="footer">
		<div class="container">
			<h2>Get in touch</h2>
			<p><span style="font-weight: bold">xuwenjia [AT] bupt.edu.cn</span><br /> Beijing University of Posts and Telecommunications<br />Beijing, China</p>
			<p></p>
			<ul class="icons">
				<li>
					<a href="https://scholar.google.com/citations?hl=zh-CN&view_op=list_works&gmla=AJsN-F7yMm5OlAmC4AgsrvACdQGDAKL16e4QE2b4shc6AFrgJxLhUpqKlGIMRBjmqI4eeQfPQHuptdiyWKBSzuC5gHwerEQD3smq--LlKeOtMuNHlBWxVuY&user=mW2Jtu0AAAAJ" class="icon fa-graduation-cap"></a>
				</li>
				<li>
					<a href="https://github.com/wenjiaXu" class="icon fa-github"></a>
				</li>
				<li>
					<a href="https://twitter.com/wenjia43411575" class="icon fa-twitter"></a>
				</li>
				<li>
					<a href="https://www.linkedin.com/in/%E6%96%87%E5%98%89-%E8%AE%B8-440867139/" class="icon fa-linkedin"></a>
				</li>
			</ul>
			<ul class="copyright">
				<li>&copy; 2022 Wenjia Xu</li>
				<!-- <li>Design: <a href="http://templated.co">TEMPLATED</a></li> -->
			</ul>
		</div>
	</footer>

</body>

</html>
